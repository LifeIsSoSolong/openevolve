{"id": "a525006a-da42-44e4-a309-20a698cfeae3", "code": "\"\"\"\nBaseline model for bean_test exp2.\n\nReads ./input/train.csv and ./input/test.csv, performs simple preprocessing\n(state encoding + months_since_crop_start), trains a LightGBM regressor, and\nwrites predictions to ./output/submission.csv with columns [year, month, state, yield].\n\nThe EVOLVE-BLOCK marks the scope that OpenEvolve is allowed to tune.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom pathlib import Path\n\n# Paths\n# PROJECT_ROOT = Path(__file__).resolve().parent\nPROJECT_ROOT = Path(r\"D:\\\u6e05\u534e\u5de5\u7a0b\u535a\u58eb\\C3I\\AutoMLAgent\\openevolve\\bean_test\\exp1\")\nINPUT_DIR = PROJECT_ROOT / \"input\"\nOUTPUT_DIR = PROJECT_ROOT / \"output\"\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\nTRAIN_PATH = INPUT_DIR / \"train.csv\"\nTEST_PATH = INPUT_DIR / \"test.csv\"\n\n# EVOLVE-BLOCK-START\nfrom typing import Dict, Tuple\nimport lightgbm as lgb\nimport pandas as pd\n\ndef encode_state(df: pd.DataFrame, mapping: Dict[str, int] | None = None) -> Tuple[pd.DataFrame, Dict[str, int]]:\n    \"\"\"Encode state column to integer IDs.\"\"\"\n    df = df.copy()\n    if mapping is None:\n        states = sorted(df[\"state\"].unique())\n        mapping = {s: i for i, s in enumerate(states)}\n    df[\"state_enc\"] = df[\"state\"].map(mapping).fillna(-1).astype(int)\n    return df, mapping\n\n\ndef months_since_crop_start(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Map month to a simple crop-phase index.\"\"\"\n    df = df.copy()\n\n    def transform(m: int) -> int:\n        return m - 10 if m >= 10 else m + 2\n\n    df[\"months_since_crop_start\"] = df[\"month\"].apply(transform)\n    return df\n\n\ndef train_and_predict() -> Path:\n\n    # ---------- read ----------\n    train = pd.read_csv(TRAIN_PATH)\n    test = pd.read_csv(TEST_PATH)\n\n    # ---------- encode & transform ----------\n    train, state2idx = encode_state(train)\n    test, _ = encode_state(test, mapping=state2idx)\n    train = months_since_crop_start(train)\n    test = months_since_crop_start(test)\n\n    # ---------- feature selection ----------\n    numeric_kinds = (\"b\", \"i\", \"u\", \"f\", \"c\")\n    candidate_features = [col for col in train.columns if col != \"yield\"]\n    features = [col for col in candidate_features if train[col].dtype.kind in numeric_kinds]\n    target = \"yield\"\n\n    # ---------- train ----------\n    models = []\n    for seed in (42, 2024):\n        m = lgb.LGBMRegressor(\n            n_estimators=1000,\n            learning_rate=0.05,\n            num_leaves=63,\n            subsample=0.8,\n            colsample_bytree=0.8,\n            random_state=seed,\n            n_jobs=-1,\n        )\n        m.fit(train[features], train[target])\n        models.append(m)\n\n    # ---------- predict ----------\n    preds = [m.predict(test[features]) for m in models]\n    test_pred = sum(preds) / len(preds)\n\n    # ---------- output ----------\n    test_out = test.copy()\n    test_out[\"yield\"] = test_pred\n    test_out = test_out[[\"year\", \"month\", \"state\", \"yield\"]]\n    out_path = OUTPUT_DIR / \"submission.csv\"\n    test_out.to_csv(out_path, index=False)\n    print(f\"\u2705 \u6a21\u578b\u8bad\u7ec3\u5b8c\u6210\uff0c\u9884\u6d4b\u7ed3\u679c\u5df2\u4fdd\u5b58\u81f3: {out_path}\")\n    return out_path\n\n# EVOLVE-BLOCK-END\n\ndef main() -> Path:\n    out_path = train_and_predict()\n    print(f\"Model trained; predictions saved to {out_path}\")\n    return out_path\n\n\nif __name__ == \"__main__\":\n    main()\n", "language": "python", "parent_id": "4234932b-5e79-4a2f-96b1-1b8027f4e4a0", "generation": 3, "timestamp": 1764741681.9924574, "iteration_found": 20, "metrics": {"combined_score": 0.8070259695522676, "mape": 7.221882911296327e-05, "rmse": 0.628335240640556}, "complexity": 0.0, "diversity": 0.0, "metadata": {"island": 1}, "prompts": null, "artifacts_json": null, "artifact_dir": null, "embedding": null}
{"id": "75a524ef-ba3f-4a40-90f1-6c482c7ce8b4", "code": "from __future__ import annotations\n\nimport logging\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error\n\ntry:  # pragma: no cover\n    from lightgbm import LGBMRegressor\nexcept ModuleNotFoundError:  # pragma: no cover\n    LGBMRegressor = None  # type: ignore\n\n\nLOGGER = logging.getLogger(__name__)\n\n\n# construct real path from judge.py's ROOT\ndef construct_real_path(root):\n    PROJECT_ROOT = Path(root)\n    INPUT_DIR = PROJECT_ROOT\n    OUTPUT_DIR = PROJECT_ROOT.parent / \"outputs\" / \"submission\"\n    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n    TRAIN_PATH = INPUT_DIR / \"train.csv\"\n    VAL_PATH = INPUT_DIR / \"val.csv\"\n    TEST_PATH = INPUT_DIR / \"test.csv\"\n    SUBMISSION_PATH = OUTPUT_DIR / \"submission.csv\"\n\n    return TRAIN_PATH, VAL_PATH, TEST_PATH, SUBMISSION_PATH\n\n\n\ndef encode_state(df: pd.DataFrame, mapping: dict[str, int] | None = None) -> tuple[pd.DataFrame, dict[str, int]]:\n    df = df.copy()\n    if mapping is None:\n        mapping = {state: idx for idx, state in enumerate(sorted(df[\"state\"].astype(str).unique()))}\n    df[\"state_enc\"] = df[\"state\"].map(mapping).fillna(-1).astype(int)\n    return df, mapping\n\n\ndef months_since_crop_start(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n    df[\"months_since_crop_start\"] = df[\"month\"].apply(lambda m: m - 10 if m >= 10 else m + 2)\n    return df\n\n\ndef _eval_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> dict[str, float]:\n    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n    mean_y = float(np.mean(y_true))\n    rrmse = float(rmse / mean_y * 100) if mean_y != 0 else float(\"nan\")\n    mask = y_true != 0\n    mape = float(np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100) if np.any(mask) else float(\"nan\")\n    return {\"rmse\": rmse, \"rrmse\": rrmse, \"mape\": mape}\n\n\ndef main(root) -> tuple[pd.DataFrame, dict[str, float]]:\n    # ---------- load ----------\n    TRAIN_PATH, VAL_PATH, TEST_PATH, _ = construct_real_path(root)\n\n    LOGGER.info(\"Loading train: %s\", TRAIN_PATH)\n    LOGGER.info(\"Loading val  : %s\", VAL_PATH)\n    LOGGER.info(\"Loading test : %s\", TEST_PATH)\n    train_df = pd.read_csv(TRAIN_PATH)\n    val_df = pd.read_csv(VAL_PATH)\n    test_df = pd.read_csv(TEST_PATH)\n\n    target = \"yield\"\n\n    # ---------- preprocess (keep behavior identical) ----------\n    train_df, state2idx = encode_state(train_df)\n    val_df, _ = encode_state(val_df, mapping=state2idx)\n    test_df, _ = encode_state(test_df, mapping=state2idx)\n\n    def _apply(df: pd.DataFrame) -> pd.DataFrame:\n        df = months_since_crop_start(df)\n        for col in [\"month_cat\", \"state_cat\", \"year_cat\"]:\n            if col in df.columns:\n                df[col] = df[col].astype(\"category\").cat.codes\n        return df\n\n    train_df = _apply(train_df)\n    val_df = _apply(val_df)\n    test_df = _apply(test_df)\n\n    features = [c for c in train_df.columns if c not in {target, \"state\"}]\n\n    # ---------- drop NaN targets in train ----------\n    before_drop = len(train_df)\n    train_df = train_df.dropna(subset=[target])\n    if len(train_df) < before_drop:\n        LOGGER.info(\"Dropped %d rows with missing target from training set\", before_drop - len(train_df))\n\n    # ---------- train (same params) ----------\n    model = LGBMRegressor(\n        n_estimators=1000,\n        learning_rate=0.05,\n        num_leaves=63,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        random_state=42,\n    )\n    model.fit(train_df[features], train_df[target])\n\n    # ---------- validate (same logic) ----------\n    metrics: dict[str, float] = {\"val_rmse\": float(\"nan\"), \"val_rrmse\": float(\"nan\"), \"val_mape\": float(\"nan\")}\n\n    if target in val_df.columns and len(val_df):\n        before_val_drop = len(val_df)\n        val_df2 = val_df.dropna(subset=[target])\n        if len(val_df2) < before_val_drop:\n            LOGGER.info(\"Dropped %d rows with missing target from validation set\", before_val_drop - len(val_df2))\n        if len(val_df2):\n            val_pred = model.predict(val_df2[features])\n            m = _eval_metrics(val_df2[target].to_numpy(), val_pred)\n            metrics.update({\"val_rmse\": m[\"rmse\"], \"val_rrmse\": m[\"rrmse\"], \"val_mape\": m[\"mape\"]})\n            LOGGER.info(\n                \"VAL -> RMSE: %.6f | rRMSE: %.6f%% | MAPE: %.6f%%\",\n                metrics[\"val_rmse\"],\n                metrics[\"val_rrmse\"],\n                metrics[\"val_mape\"],\n            )\n        else:\n            LOGGER.info(\"Validation set has target column but all targets are NaN; skip metrics\")\n    else:\n        LOGGER.info(\"Validation set has no target column '%s'; skip val metrics\", target)\n\n    # ---------- inference + submission ----------\n    preds = model.predict(test_df[features])\n    submission = test_df[[\"year\", \"month\", \"state\"]].copy()\n    submission[target] = preds\n\n    return submission, metrics\n\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(name)s - %(message)s\")\n    root = r\"D:\\\u6e05\u534e\u5de5\u7a0b\u535a\u58eb\\C3I\\daguan\\agentic-rl\\mle-openevolve\\experiments\\bean04\\baseline\\2months\"\n\n    submission, metrics = main(root)\n\n    _, _, _, SUBMISSION_PATH = construct_real_path(root)\n    submission.to_csv(SUBMISSION_PATH, index=False)\n    LOGGER.info(\"Saved submission -> %s\", SUBMISSION_PATH)\n    LOGGER.info(\"Metrics dict -> %s\", metrics)", "language": "python", "parent_id": null, "generation": 0, "timestamp": 1766113848.558616, "iteration_found": 0, "metrics": {"combined_score": 0.1320547368666422, "rmse": 129.56359446061253, "rrmse": 3.918173520744148, "mape": 2.8993899544864554}, "complexity": 0.0, "diversity": 0.0, "metadata": {"island": 0}, "prompts": null, "artifacts_json": null, "artifact_dir": null, "embedding": null}